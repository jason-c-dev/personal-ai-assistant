{
  "version": "1.0",
  "description": "AI model configuration and provider settings for the Personal AI Assistant",
  "last_updated": "2024-06-15",
  
  "default_provider": "anthropic",
  
  "providers": {
    "anthropic": {
      "name": "Anthropic Claude",
      "api_base": "https://api.anthropic.com",
      "models": {
        "claude-3-sonnet-20240229": {
          "display_name": "Claude 3 Sonnet",
          "context_window": 200000,
          "max_output_tokens": 4096,
          "recommended_use": "Balanced performance and capability - best for most users",
          "cost_per_1k_tokens": {
            "input": 0.003,
            "output": 0.015
          }
        },
        "claude-3-haiku-20240307": {
          "display_name": "Claude 3 Haiku",
          "context_window": 200000,
          "max_output_tokens": 4096,
          "recommended_use": "Fastest responses, good for simple conversations",
          "cost_per_1k_tokens": {
            "input": 0.00025,
            "output": 0.00125
          }
        },
        "claude-3-opus-20240229": {
          "display_name": "Claude 3 Opus",
          "context_window": 200000,
          "max_output_tokens": 4096,
          "recommended_use": "Highest quality responses, complex reasoning",
          "cost_per_1k_tokens": {
            "input": 0.015,
            "output": 0.075
          }
        }
      },
      "default_model": "claude-3-sonnet-20240229",
      "supports_system_messages": true,
      "supports_tool_use": true,
      "authentication": "api_key"
    },
    
    "openai": {
      "name": "OpenAI GPT",
      "api_base": "https://api.openai.com/v1",
      "models": {
        "gpt-4-turbo-preview": {
          "display_name": "GPT-4 Turbo",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "recommended_use": "High quality responses, good reasoning capabilities",
          "cost_per_1k_tokens": {
            "input": 0.01,
            "output": 0.03
          }
        },
        "gpt-4": {
          "display_name": "GPT-4",
          "context_window": 8192,
          "max_output_tokens": 4096,
          "recommended_use": "Proven performance, smaller context window",
          "cost_per_1k_tokens": {
            "input": 0.03,
            "output": 0.06
          }
        },
        "gpt-3.5-turbo": {
          "display_name": "GPT-3.5 Turbo",
          "context_window": 16385,
          "max_output_tokens": 4096,
          "recommended_use": "Fast and economical, good for basic conversations",
          "cost_per_1k_tokens": {
            "input": 0.0005,
            "output": 0.0015
          }
        }
      },
      "default_model": "gpt-4-turbo-preview",
      "supports_system_messages": true,
      "supports_tool_use": true,
      "authentication": "api_key"
    },
    
    "bedrock": {
      "name": "AWS Bedrock",
      "api_base": "https://bedrock-runtime.{region}.amazonaws.com",
      "models": {
        "anthropic.claude-3-sonnet-20240229-v1:0": {
          "display_name": "Claude 3 Sonnet (Bedrock)",
          "context_window": 200000,
          "max_output_tokens": 4096,
          "recommended_use": "AWS integrated Claude, good for enterprise",
          "provider_name": "Anthropic",
          "cost_per_1k_tokens": {
            "input": 0.003,
            "output": 0.015
          }
        },
        "anthropic.claude-3-haiku-20240307-v1:0": {
          "display_name": "Claude 3 Haiku (Bedrock)",
          "context_window": 200000,
          "max_output_tokens": 4096,
          "recommended_use": "Fast AWS Claude, economical option",
          "provider_name": "Anthropic",
          "cost_per_1k_tokens": {
            "input": 0.00025,
            "output": 0.00125
          }
        }
      },
      "default_model": "anthropic.claude-3-sonnet-20240229-v1:0",
      "supports_system_messages": true,
      "supports_tool_use": true,
      "authentication": "aws_credentials",
      "regions": ["us-east-1", "us-west-2", "eu-west-1", "ap-southeast-1"]
    }
  },
  
  "response_parameters": {
    "default": {
      "temperature": 0.7,
      "top_p": 0.95,
      "max_tokens": 4000,
      "stop_sequences": [],
      "stream": false
    },
    
    "creative": {
      "temperature": 0.9,
      "top_p": 0.95,
      "max_tokens": 4000,
      "description": "More creative and varied responses"
    },
    
    "precise": {
      "temperature": 0.3,
      "top_p": 0.9,
      "max_tokens": 4000,
      "description": "More focused and consistent responses"
    },
    
    "concise": {
      "temperature": 0.7,
      "top_p": 0.95,
      "max_tokens": 2000,
      "description": "Shorter, more direct responses"
    },
    
    "detailed": {
      "temperature": 0.7,
      "top_p": 0.95,
      "max_tokens": 6000,
      "description": "Longer, more comprehensive responses"
    }
  },
  
  "memory_integration": {
    "context_management": {
      "max_context_tokens": 100000,
      "context_window_overlap": 1000,
      "memory_priority_weighting": {
        "user_profile": 1.0,
        "active_context": 0.9,
        "recent_interactions": 0.8,
        "preferences_patterns": 0.7,
        "life_context": 0.6,
        "relationship_evolution": 0.5
      }
    },
    
    "memory_condensation": {
      "trigger_threshold_tokens": 80000,
      "condensation_ratio": 0.3,
      "preserve_high_importance": true,
      "minimum_importance_preserve": 7
    },
    
    "retrieval_settings": {
      "max_memories_per_response": 10,
      "relevance_threshold": 0.6,
      "time_decay_factor": 0.1,
      "importance_boost_factor": 0.3
    }
  },
  
  "conversation_flow": {
    "session_initialization": {
      "memory_review_timeout_seconds": 5,
      "max_startup_memories": 20,
      "greeting_personalization": true
    },
    
    "response_generation": {
      "include_reasoning": false,
      "show_memory_references": false,
      "context_acknowledgment": "subtle",
      "follow_up_suggestions": true
    },
    
    "memory_updates": {
      "auto_update_after_response": true,
      "update_timeout_seconds": 3,
      "batch_updates": true,
      "importance_scoring_model": "rule_based"
    }
  },
  
  "performance_settings": {
    "timeouts": {
      "api_request_timeout": 30,
      "memory_operation_timeout": 5,
      "session_timeout_minutes": 60
    },
    
    "retry_logic": {
      "max_retries": 3,
      "backoff_strategy": "exponential",
      "retry_status_codes": [429, 500, 502, 503, 504]
    },
    
    "caching": {
      "cache_responses": false,
      "cache_memory_lookups": true,
      "cache_duration_minutes": 10
    }
  },
  
  "safety_and_moderation": {
    "content_filtering": {
      "enabled": true,
      "filter_level": "moderate",
      "custom_filters": []
    },
    
    "rate_limiting": {
      "requests_per_minute": 60,
      "tokens_per_minute": 100000,
      "burst_allowance": 10
    },
    
    "privacy_protection": {
      "anonymize_sensitive_data": false,
      "memory_encryption": false,
      "audit_logging": true
    }
  },
  
  "experimental_features": {
    "semantic_search": {
      "enabled": false,
      "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
      "vector_db_path": "system/embeddings"
    },
    
    "advanced_reasoning": {
      "chain_of_thought": true,
      "self_reflection": false,
      "uncertainty_quantification": true
    },
    
    "multimodal": {
      "image_analysis": false,
      "voice_input": false,
      "document_analysis": false
    }
  },
  
  "development_settings": {
    "debug_mode": false,
    "verbose_logging": false,
    "performance_monitoring": false,
    "mock_api_responses": false,
    "test_memory_path": "./test_memory"
  }
} 